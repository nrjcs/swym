{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kolkata_pre.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nrjcs/swym/blob/master/swym_pre.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "jWFHkeBhtDYR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Using pre-trained models\n",
        "\n",
        "> data by ImageNet project: \n",
        ">> provide a large image database for research purposes\n",
        ">> more than 14 million images\n",
        ">> more than 20,000 classes\n",
        "\n",
        "> winners of ImageNet Large Scale Visual Recognition Challenge ( ILSVRC ) release their models such as AlexNet, VGGNet, Inception, ResNet, Xception \n",
        "\n",
        "> Keras supports to many models (architecture)\n",
        "> weights file is automatically downloaded ( one-time )\n",
        "\n",
        "This notebook is not\n",
        "> Transfer Learning \n",
        "> Fine-tuning"
      ]
    },
    {
      "metadata": {
        "id": "zUkNWsvDswRx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "** Source**\n",
        "\n",
        "> https://github.com/spmallick/learnopencv/blob/master/Keras-ImageNet-Models/pretrained-imagenet-models-classification.ipynb"
      ]
    },
    {
      "metadata": {
        "id": "06IZSW01qjIC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "\n",
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lgMNSShHoqN0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load the models from keras applications folder\n",
        "\n",
        "from keras.applications import vgg16, inception_v3, resnet50, mobilenet\n",
        "\n",
        "vgg_model = vgg16.VGG16(weights='imagenet')\n",
        "\n",
        "inception_model = inception_v3.InceptionV3(weights='imagenet')\n",
        "\n",
        "resnet_model = resnet50.ResNet50(weights='imagenet')\n",
        "\n",
        "mobilenet_model = mobilenet.MobileNet(weights='imagenet')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HEBjUjvWpDFx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Import the required image preprocessing functions\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.applications.imagenet_utils import decode_predictions\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "filename = '/content/drive/My Drive/pre_image/cat.jpg'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5mekN5VatjdN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Perform Pre-processing before feeding the image to the network\n",
        "\n",
        "---\n",
        "> Keras loads the image using PIL library. This is done using the load_img function. The image is in width x height x channels format.\n",
        "> Convert the image from PIL format to Numpy format ( height x width x channels ) using image_to_array function.\n",
        "> Form a batch of image( s ) to feed the network. This is done using the expand_dims function in Numpy"
      ]
    },
    {
      "metadata": {
        "id": "QeN6HuGOrUtn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# load an image in PIL format\n",
        "original = load_img(filename, target_size=(224, 224))\n",
        "print('PIL image size',original.size)\n",
        "plt.imshow(original)\n",
        "plt.show()\n",
        "\n",
        "# convert the PIL image to a numpy array\n",
        "# IN PIL - image is in (width, height, channel)\n",
        "# In Numpy - image is in (height, width, channel)\n",
        "numpy_image = img_to_array(original)\n",
        "plt.imshow(np.uint8(numpy_image))\n",
        "plt.show()\n",
        "print('numpy array size',numpy_image.shape)\n",
        "\n",
        "# Convert the image / images into batch format\n",
        "# expand_dims will add an extra dimension to the data at a particular axis\n",
        "# We want the input matrix to the network to be of the form (batchsize, height, width, channels)\n",
        "# Thus we add the extra dimension to the axis 0.\n",
        "image_batch = np.expand_dims(numpy_image, axis=0)\n",
        "print('image batch size', image_batch.shape)\n",
        "plt.imshow(np.uint8(image_batch[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Cc5DoCYVuBN2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Predictions using the various Network"
      ]
    },
    {
      "metadata": {
        "id": "e-8Gxw2-rvij",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# prepare the image for the VGG model\n",
        "processed_image = vgg16.preprocess_input(image_batch.copy())\n",
        "\n",
        "# get the predicted probabilities for each class\n",
        "predictions = vgg_model.predict(processed_image)\n",
        "# print predictions\n",
        "# convert the probabilities to class labels\n",
        "# We will get top 5 predictions which is the default\n",
        "label_vgg = decode_predictions(predictions)\n",
        "label_vgg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r1dK3gHvsDeS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# prepare the image for the ResNet50 model\n",
        "processed_image = resnet50.preprocess_input(image_batch.copy())\n",
        "\n",
        "# get the predicted probabilities for each class\n",
        "predictions = resnet_model.predict(processed_image)\n",
        "\n",
        "# convert the probabilities to class labels\n",
        "# If you want to see the top 3 predictions, specify it using the top argument\n",
        "label_resnet = decode_predictions(predictions, top=3)\n",
        "label_resnet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SreeB94hsPGH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# prepare the image for the MobileNet model\n",
        "processed_image = mobilenet.preprocess_input(image_batch.copy())\n",
        "\n",
        "# get the predicted probabilities for each class\n",
        "predictions = mobilenet_model.predict(processed_image)\n",
        "\n",
        "# convert the probabilities to imagenet class labels\n",
        "label_mobilenet = decode_predictions(predictions)\n",
        "label_mobilenet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IbTKxI4osggp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# load an image in PIL format\n",
        "original = load_img(filename, target_size=(299, 299))\n",
        "\n",
        "# Convert the PIL image into numpy array\n",
        "numpy_image = img_to_array(original)\n",
        "\n",
        "# reshape data in terms of batchsize\n",
        "image_batch = np.expand_dims(numpy_image, axis=0)\n",
        "\n",
        "# prepare the image for the Inception model\n",
        "processed_image = inception_v3.preprocess_input(image_batch.copy())\n",
        "\n",
        "# get the predicted probabilities for each class\n",
        "predictions = inception_model.predict(processed_image)\n",
        "\n",
        "# convert the probabilities to class labels\n",
        "label_inception = decode_predictions(predictions)\n",
        "label_inception"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1ibTjVUbsUoU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "numpy_image = np.uint8(img_to_array(original)).copy()\n",
        "numpy_image = cv2.resize(numpy_image,(900,900))\n",
        "\n",
        "cv2.putText(numpy_image, \"VGG16: {}, {:.2f}\".format(label_vgg[0][0][1], label_vgg[0][0][2]) , (350, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 3)\n",
        "cv2.putText(numpy_image, \"MobileNet: {}, {:.2f}\".format(label_mobilenet[0][0][1], label_mobilenet[0][0][2]) , (350, 75), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 3)\n",
        "cv2.putText(numpy_image, \"Inception: {}, {:.2f}\".format(label_inception[0][0][1], label_inception[0][0][2]) , (350, 110), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 3)\n",
        "cv2.putText(numpy_image, \"ResNet50: {}, {:.2f}\".format(label_resnet[0][0][1], label_resnet[0][0][2]) , (350, 145), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 3)\n",
        "numpy_image = cv2.resize(numpy_image, (700,700))\n",
        "cv2.imwrite(\"images/{}_output.jpg\".format(filename.split('/')[-1].split('.')[0]),cv2.cvtColor(numpy_image, cv2.COLOR_RGB2BGR))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BZUPL8pIsqfK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=[10,10])\n",
        "plt.imshow(numpy_image)\n",
        "plt.axis('off')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}