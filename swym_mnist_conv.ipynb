{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "swym_mnist_conv.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nrjcs/swym/blob/master/swym_mnist_conv.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "_kjTsII0qfuL",
        "colab_type": "code",
        "outputId": "7d3dc64a-14ee-4b5e-abae-94a6a4580306",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "cell_type": "code",
      "source": [
        "#....................................................................#\n",
        "#  keras mnist digit classification with convolution neural network  #\n",
        "#....................................................................#\n",
        "\n",
        "\n",
        "#Load the dataset => as in the case of FCNN\n",
        "# -- Keras provides in-built support to many datasets\n",
        "# -- such as MNIST (Modified National Institute of Standards and Technology database) @ http://yann.lecun.com/exdb/mnist/\n",
        "\t# database of handwritten digits\n",
        "\t# used  extensively in optical character recognition and machine learning research\n",
        "\t# training set of 60,000 examples, and a test set of 10,000 examples\n",
        "\t# digits have been size-normalized and centered in a fixed-size image\n",
        "\t# black and white digits\n",
        "\t# 28 x 28  pixels\n",
        "\t# Keras provides method to load MNIST data set\n",
        "  \n",
        "from keras.datasets import mnist\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data() \t#Keras function\n",
        "\n",
        "print (\"mnist data downloaded...\")\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 1s 0us/step\n",
            "mnist data downloaded...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1PetdwiQsDjq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Print shape of dataset..it will print three tuples, namely the no. of images in dataset, height and width(60000, 28, 28)\n",
        "\n",
        "print (X_train.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3CwHiVn9sonK",
        "colab_type": "code",
        "outputId": "d9e8c57c-4bd4-4638-a104-dced9fe5c00c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 912
        }
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# plot images...subplot function is being used...nice documentation is available on the official webpage of matplotlib\n",
        "# arguments to subplot functions are number of rows, number of columns and number of subplots in the plot...comma is mandatory if values are less than 10\n",
        "# you can experiment\n",
        "# uncomment if do not want to print\n",
        "plt.subplot(221)\t\n",
        "plt.imshow(X_train[50], cmap=plt.get_cmap('gray')) # ploting first image of training data set\n",
        "plt.subplot(222)\n",
        "plt.imshow(X_train[1304], cmap=plt.get_cmap('gray'))\t# ploting 135th image in training data set\n",
        "plt.subplot(223)\n",
        "plt.imshow(X_test[244], cmap=plt.get_cmap('gray'))\t# ploting 2445th image of test date set\n",
        "plt.subplot(224)\n",
        "plt.imshow(X_test[39], cmap=plt.get_cmap('gray'))\t# ploting 4th image of test data set\n",
        "# show the plot\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-38641c45703e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# uncomment if do not want to print\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m221\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_cmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# ploting first image of training data set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m222\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1304\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_cmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m# ploting 135th image in training data set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, data, **kwargs)\u001b[0m\n\u001b[1;32m   2699\u001b[0m         \u001b[0mfilternorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilternorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimlim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimlim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2700\u001b[0m         resample=resample, url=url, **({\"data\": data} if data is not\n\u001b[0;32m-> 2701\u001b[0;31m         None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2702\u001b[0m     \u001b[0msci\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__ret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2703\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m__ret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1808\u001b[0m                         \u001b[0;34m\"the Matplotlib list!)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1810\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1812\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5492\u001b[0m                               resample=resample, **kwargs)\n\u001b[1;32m   5493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5494\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5495\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    644\u001b[0m         if not (self._A.ndim == 2\n\u001b[1;32m    645\u001b[0m                 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):\n\u001b[0;32m--> 646\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid dimensions for image data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_A\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Invalid dimensions for image data"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAALUAAACrCAYAAAAgj91CAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nqNRiHJVajKNSi3FUajHOfwtK8tjOmc/9AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "2xwxGQy2sFIc",
        "colab_type": "code",
        "outputId": "125680d8-dd77-4a38-d05b-99c91e54853d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "cell_type": "code",
      "source": [
        "# defining some parameters\n",
        "img_rows, img_cols = 28,28\n",
        "\n",
        "# data preprocessing\n",
        "#reshaping the data...Normalize images\n",
        "X_train = X_train.reshape(60000,28,28,1)\n",
        "X_test = X_test.reshape(10000,28,28,1)\n",
        "\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "print('X_train shape:', X_train.shape)\n",
        "print('x_test shape:', X_test.shape)\n",
        "print(X_train.shape[0], 'train samples')\n",
        "print(X_test.shape[0], 'test samples')\n",
        "\n",
        "input_shape = (img_rows, img_cols, 1)\n",
        "num_classes = 10\n",
        "\n",
        "\n",
        "\n",
        "import keras.utils\n",
        "#Convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train shape: (60000, 28, 28, 1)\n",
            "x_test shape: (10000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QmOvzxYp6MyI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# for reference reproducing from https://keras.io/layers/convolutional/\n",
        "\n",
        "# keras.layers.Conv2D(filters, kernel_size, strides=(1, 1), padding='valid', \n",
        "    # activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', ..... )\n",
        "  \n",
        "# creates a convolution kernel that is convolved with the layer input to produce a tensor of outputs. \n",
        "# If use_bias is True, a bias vector is created and added to the outputs. \n",
        "# Finally, if activation is not None, it is applied to the outputs as well.\n",
        "\n",
        "# if first layer, provide the keyword argument input_shape e.g. input_shape=(128, 128, 3) for 128x128 RGB\n",
        "\n",
        "# filters: Integer, the dimensionality of the output space (i.e. the number of output filters in the convolution).\n",
        "# kernel_size: An integer or tuple/list of 2 integers, specifying the height and width of the 2D convolution window. \n",
        "    # Can be a single integer to specify the same value for all spatial dimensions.\n",
        "# strides: An integer or tuple/list of 2 integers, specifying the strides of the convolution along the height and width. \n",
        "    # Can be a single integer to specify the same value for all spatial dimensions.\n",
        "# padding: one of \"valid\" or \"same\" (case-insensitive).\n",
        "# activation: Activation function to use. If you don't specify anything, no activation is applied (ie. \"linear\" activation: a(x) = x).\n",
        "# use_bias: Boolean, whether the layer uses a bias vector.\n",
        "# kernel_initializer: Initializer for the kernel weights matrix.\n",
        "# bias_initializer: Initializer for the bias vector.\n",
        "\n",
        "## filters and kernel_size parameters are compulsory\n",
        "\n",
        "\n",
        "\n",
        "# MaxPooling2D reproduced from https://keras.io/layers/pooling/\n",
        "# keras.layers.MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid', data_format=None)\n",
        "\n",
        "# pool_size: integer or tuple of 2 integers, factors by which to downscale (vertical, horizontal). \n",
        "      # If only one integer is specified, the same window length will be used for both dimensions.\n",
        "# strides: Integer, tuple of 2 integers, or None. Strides values. If None, it will default to pool_size.\n",
        "# padding: One of \"valid\" or \"same\"\n",
        "# data_format: A string, one of channels_last (default) or channels_first. The ordering of the dimensions in the inputs.  channels_last\n",
        "        # corresponds to inputs with shape  (batch, height, width, channels) while channels_first corresponds to inputs with shape  \n",
        "        # (batch, channels, height, width). It defaults to the image_data_format value found in your Keras config file at \n",
        "        # ~/.keras/keras.json. If you never set it, then it will be \"channels_last\".\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FtPgp5lStzjk",
        "colab_type": "code",
        "outputId": "86d555ee-6f94-4749-958f-4d15595f2ba7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Define model architecture\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "#arch 1\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten()) #Flattens the input\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "#arch 2\n",
        "#model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
        "#model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "#model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "#model.add(Dropout(0.25))\n",
        "#model.add(Flatten()) # Flattens the input\n",
        "#model.add(Dense(128, activation='relu'))\n",
        "#model.add(Dropout(0.5))\n",
        "#model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "print (\"keep going...\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "keep going...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kl0RQYZyuHE1",
        "colab_type": "code",
        "outputId": "7da12224-4d4c-4b4c-dc70-c439e4f239ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# compiling model\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adadelta(), metrics=['accuracy'])\n",
        "\n",
        "print (\"compile successful...\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "compile successful...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dRCZOEUmuKCD",
        "colab_type": "code",
        "outputId": "cb7179a1-93a9-48f6-f008-4e430b54bcd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "epochs = 2\n",
        "\n",
        "# taining the network\n",
        "\n",
        "history=model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_split=0.2)\n",
        "\n",
        "print (\"training done...\")\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/2\n",
            "48000/48000 [==============================] - 122s 3ms/step - loss: 0.2584 - acc: 0.9217 - val_loss: 0.0827 - val_acc: 0.9771\n",
            "Epoch 2/2\n",
            "48000/48000 [==============================] - 122s 3ms/step - loss: 0.0703 - acc: 0.9789 - val_loss: 0.0635 - val_acc: 0.9802\n",
            "training done...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lEmU2ZbBuT5M",
        "colab_type": "code",
        "outputId": "81a50003-f513-43f0-ce08-eda2c14fb2c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "cell_type": "code",
      "source": [
        "# evaluating the model\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=1)\n",
        "print('loss:', score[0])\n",
        "print('accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 7s 737us/step\n",
            "loss: 0.0531598847608082\n",
            "accuracy: 0.9821\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "npPQMD752vA9",
        "colab_type": "code",
        "outputId": "38904204-cc6b-440c-8525-b30be80d4352",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        }
      },
      "cell_type": "code",
      "source": [
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 24, 24, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 9216)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                92170     \n",
            "=================================================================\n",
            "Total params: 110,986\n",
            "Trainable params: 110,986\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LdB0OsTOeDga",
        "colab_type": "code",
        "outputId": "c265a496-33e5-4a0c-d263-e005a78618b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# list all data in history\n",
        "print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-9a91e1d728fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# summarize history for accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "YLuTzBk7-K3w",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " Improving Performance\n",
        " \n",
        " > Different architecture provided in code\n",
        " \n",
        ">  Number of layers\n",
        "\n",
        "> Different layers: dropout etc.\n",
        "\n",
        "> Different hperparameters: number of filters, stride, and padding\n",
        "\n",
        "> Different learning rate for optimizer\n",
        "\n",
        "> batch size\n",
        "\n",
        "> with different optimizers\n",
        "\n",
        "> with more number of epochs\n",
        "\n",
        "> Controlling the optimizer learning rate\n",
        "\n",
        "> Increasing the size of batch computation\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}