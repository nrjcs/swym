{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "swym_mnist_fcnn.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nrjcs/swym/blob/master/swym_mnist_fcnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "P2IrTN4gCcew",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#basic fully connected neural network for mnist digit classification\n",
        "\n",
        "## nice documentation is available at https://keras.io/\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "70EjjPgoKkB9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## -- Keras provides in-built support to many datasets\n",
        "## -- such as MNIST (Modified National Institute of Standards and Technology database) @ http://yann.lecun.com/exdb/mnist/\n",
        "\t# database of handwritten digits\n",
        "\t# used  extensively in optical character recognition and machine learning research\n",
        "\t# training set of 60,000 examples, and a test set of 10,000 examples\n",
        "\t# digits have been size-normalized and centered in a fixed-size image\n",
        "\t# black and white digits\n",
        "\t# 28 x 28  pixels\n",
        "\t# Keras provides method to load MNIST data set"
      ]
    },
    {
      "metadata": {
        "id": "tKWVb27vAeL7",
        "colab_type": "code",
        "outputId": "24e48f6c-c587-438d-dffc-918d24dd51f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "# load MNIST data set\n",
        "from keras.datasets import mnist\t \t#dataset\n",
        "\n",
        "(X_train, Y_train), (X_test, Y_test) = mnist.load_data() \t#Keras function\n",
        "\n",
        "print (\"mnist data downloaded...\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "mnist data downloaded...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0I33vNMnK1TZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### plot images...\n",
        "\n",
        "> subplot function is being used\n",
        "\n",
        "> nice documentation is available on the official webpage of matplotlib\n",
        "\n",
        "> arguments to subplot functions are number of rows, number of columns and number of subplots in the plot\n",
        "\n",
        "> comma is mandatory if values are less than 10\n"
      ]
    },
    {
      "metadata": {
        "id": "PuUhUPFTAjbq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "outputId": "e7b7c032-2523-4c9e-d10a-cc3b7123c126"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# comment if do not want to print\n",
        "\n",
        "import matplotlib.pyplot as plt\t\t\t#to plot images\n",
        "\n",
        "plt.subplot(221)\t\n",
        "plt.imshow(X_train[50], cmap=plt.get_cmap('gray')) # ploting first image of training data set\n",
        "plt.subplot(222)\n",
        "plt.imshow(X_train[1304], cmap=plt.get_cmap('gray'))\t# ploting 135th image in training data set\n",
        "plt.subplot(223)\n",
        "plt.imshow(X_test[244], cmap=plt.get_cmap('gray'))\t# ploting 2445th image of test date set\n",
        "plt.subplot(224)\n",
        "plt.imshow(X_test[39], cmap=plt.get_cmap('gray'))\t# ploting 4th image of test data set\n",
        "# show the plot\n",
        "plt.show()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZwAAAFLCAYAAADiejquAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYAUNBwBgBQ0HAGAFDQcAYMX/AxExy5ICVa3OAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x396 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "TfwO2jCdAghp",
        "colab_type": "code",
        "outputId": "437af789-9cdc-4530-af5b-6b1087961a4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Print shape of dataset..it will print three tuples, namely the no. of images in dataset, height and width(60000, 28, 28)\n",
        "\n",
        "print (X_train.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "c4Uz0kTQAmtB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5b0e0a22-11ae-4d4e-e373-81412de854cc"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# Step 3: Preprocess input data for Keras\n",
        "\n",
        "# flatten 28*28 images to a 784 vector for each image and pixel precision set to 32 bit\n",
        "num_pixels = X_train.shape[1] * X_train.shape[2]\n",
        "X_train = X_train.reshape(X_train.shape[0], num_pixels).astype('float32')\n",
        "X_test = X_test.reshape(X_test.shape[0], num_pixels).astype('float32')\n",
        "\n",
        "# normalize inputs from 0-255 to 0-1\n",
        "X_train = X_train / 255\n",
        "X_test = X_test / 255\n",
        "\n",
        "# Step 4: Preprocess class labels\n",
        "# check shape of our class label data\n",
        "\n",
        "print (Y_train.shape)\n",
        "#We should have 10 different classes, one for each digit, but it looks like we only have a 1-dimensional array.\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eU5LFemhAsiA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "96e3bab2-7122-4d33-a61d-1b85455ba18a"
      },
      "cell_type": "code",
      "source": [
        "#check labels for the first 10 training samples:\n",
        "print (Y_train[:10])\n",
        "# output of the form [5 0 4 1 9 2 1 3 1 4]\n",
        "#The Y_train and Y_test data are not split into 10 distinct class labels, but rather are represented as a single array with the class values."
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[5 0 4 1 9 2 1 3 1 4]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8MKhIS3vAuW9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "1e455f18-92fc-48fa-e471-29111a0db615"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "from keras.utils import np_utils\t\t#for transforming data \n",
        "\n",
        "# Convert 1-dimensional class arrays to 10-dimensional class matrices\n",
        "Y_train = np_utils.to_categorical(Y_train)\n",
        "Y_test = np_utils.to_categorical(Y_test)\n",
        "num_classes = Y_test.shape[1]\n",
        "\n",
        "# check again\t\n",
        "print (Y_train.shape)\n",
        "# (60000, 10)\n",
        "print (Y_train[:5])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 10)\n",
            "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KDjnsR5vLdqL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "### a very simple model is being created in next few lines...this is the most important part => creating a good network\n",
        "\n",
        "### Use sequential model\n",
        ">  a Sequential model is declared as\n",
        ">>        model = Sequential()\n",
        "then dense layers are added\n",
        "\n",
        "\n",
        "> Dense implements the operation: output = activation(dot(input, kernel) + bias) \n",
        "           >>  activation is the element-wise activation function passed as the activation argument\n",
        "           >>  kernel is a weights matrix created by the layer\n",
        "           >>  bias is a bias vector created by the layer (only applicable if use_bias is True)\n",
        "      \n",
        "> adding layers (can be combined with layer declaration as well)\n",
        ">>         model = Sequential([Dense(32, input_shape=(784,)), Activation('relu'),Dense(10), Activation('softmax'),])\n",
        " \n",
        "\n",
        ">> > Or\n",
        "\n",
        ">>         model.add(Dense(32, input_dim=784))\n",
        ">>         model.add(Activation('relu'))\n",
        "\n",
        "> model needs to know what input shape it should expect\n",
        "\n",
        ">> first layer in a Sequential model (and only the first, because following layers can do automatic shape inference) needs to receive information about its input shape\n",
        "\n",
        "\n",
        "> Dense(32, input_dim=784) specifies that it is \n",
        "\t\t>> first (input) layer\n",
        "        \n",
        "  >> output dimension is 32 ($1^{st}$ argument \n",
        "    \n",
        ">> input dimension is 784\n",
        "\n",
        "   >> kernel_initializer: Initializations define the way to set the initial random weights of Keras layers.\n",
        "    \n",
        "   >> kernel_initializer='normal': name of initialization function for the weights of the layer. normal for values \n",
        "    \n",
        "   >> randomly drawn from normal distribution.\n",
        "   \n",
        "   >> many more intializers: Zeros, Ones, normal, Constant, normal , and many more\n",
        "    \n",
        "   >> If no activation function specified, no activation is applied (ie. \"linear\" activation: a(x) = x).\n",
        "\n",
        "\n",
        "> activations: Activations can either be used through an Activation layer, or through the activation argument supported by all forward layers:    \n",
        ">> many activation function are available in Keras: relu, softmax, sigmoid, tanh, so on"
      ]
    },
    {
      "metadata": {
        "id": "yKcp5iXTAyyZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "34910a5c-8231-4eab-a089-dd5dd77e13d3"
      },
      "cell_type": "code",
      "source": [
        "# Define model architecture\n",
        "\n",
        "from keras.models import Sequential\t\t#model\n",
        "from keras.layers import Dense\t\t\t#layer\n",
        "from keras.layers import Dropout\t\t#layer\n",
        "from keras import initializers      # for importing initializers of keras\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(num_pixels, input_dim=num_pixels, kernel_initializer=initializers.RandomNormal(), activation='relu')) #only one hidden layer with relu as activation function\n",
        "#model.add(Dense(num_pixels, input_dim=num_pixels, kernel_initializer=initializers.Constant(value=5), activation='relu')) #only one hidden layer with relu as activation function\t\n",
        "model.add(Dense(num_classes, kernel_initializer='normal', activation='softmax'))\t\t\t\t\t#output layer with softmax as activation function\n",
        "\n",
        "\n",
        "#print(model.summary())\n",
        "\n",
        "print (\"congrts model defined...\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "congrts model defined...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GZOI0ZQSM-Nv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Before training, configure the learning process, using compile() method. Three argements:\n",
        "    > loss function: the objective function that model try to minimize\n",
        "          >> many more: categorical_crossentropy, mean_squared_error, mean_squared_logarithmic_error, ......\n",
        "    > optimizer: ANN training process is an optimization task with the aim of finding a set of weights to minimize some \n",
        "    > objective function\n",
        "          >> determine how weights are updated\n",
        "          >> many more: adam (Adaptive moment estimation), sgd (Stochastic gradient descent), \n",
        "    > list of metrics: used to judge performance of model, similar to objective function however not used for training purpose\n",
        "      \n",
        "### optimizer, loss function, meterics => very important step which will determine the performance of your network"
      ]
    },
    {
      "metadata": {
        "id": "pFg3NWWpA04y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a006fae5-14aa-49c0-e66e-f190089a690d"
      },
      "cell_type": "code",
      "source": [
        "# Compile model\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
        "\n",
        "print (\"Compilation done ...\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Compilation done ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rE4bnbsYNSM4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "> training, validation, test\n",
        "\n",
        "> multiple variations of the model is trained on the training dataset => parameter tuning\n",
        "\n",
        "> one of the variation is chosen based performance on the validation set => model selection\n",
        "\n",
        "> evaluation on test set\n",
        "\n",
        "> epoch: number of times learning algorithm sees entire data\n",
        "\n",
        "> batch size: number of samples processed before updating weights\n",
        "\n",
        "> By setting verbose 0, 1 or 2 you just say how do you want to 'see' the training progress for each epoch. (no information, animated bar, numbe of epochs) )"
      ]
    },
    {
      "metadata": {
        "id": "cSh9LnquA22y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "88ac05da-1904-4313-8b36-32f3574563b0"
      },
      "cell_type": "code",
      "source": [
        "#Train model\n",
        "\n",
        "\n",
        "model.fit(X_train, Y_train,validation_split=0.2, epochs=2, batch_size=200, verbose=1)\n",
        "\n",
        "\n",
        "print (\"parameter tuning done...\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/2\n",
            "48000/48000 [==============================] - 6s 122us/step - loss: 0.3105 - acc: 0.9125 - val_loss: 0.1703 - val_acc: 0.9526\n",
            "Epoch 2/2\n",
            "48000/48000 [==============================] - 5s 107us/step - loss: 0.1238 - acc: 0.9648 - val_loss: 0.1112 - val_acc: 0.9673\n",
            "parameter tuning done...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "q_u0OQ53A4_x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e23665b3-a4b6-4078-8dab-d4cb2a83290e"
      },
      "cell_type": "code",
      "source": [
        "# Step 8: Evaluate model\n",
        "scores = model.evaluate(X_test, Y_test)\n",
        "print(\"Error: %.2f%%\" % (100-scores[1]*100))\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 63us/step\n",
            "Error: 3.08%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Oa-y7lxnm0t5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e12ed68d-64b9-4c75-be8d-f514748e17db"
      },
      "cell_type": "code",
      "source": [
        "print(model.metrics_names)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['loss', 'acc']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5TTXar8dFT7Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "f611a339-657a-468a-af1f-333ffd3f1b48"
      },
      "cell_type": "code",
      "source": [
        "print (model.summary())"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 784)               615440    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                7850      \n",
            "=================================================================\n",
            "Total params: 623,290\n",
            "Trainable params: 623,290\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IyVr7wpzBAMt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Additional**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "=> Improving Performance of Simple Network: additional hidden layers (add one more dense layer)\n",
        " \n",
        "     model.add(Dense(num_classes, kernel_initializer='normal', activation='relu'))\n",
        "     \n",
        "=> Improving Performance of Simple Network: additional hidden layers (add one more dense layer)\n",
        "\n",
        "     model.add(Dense(num_classes, kernel_initializer='normal', activation='tanh'))\n",
        "\n",
        "=> Improving Performance of Simple Network: introducing dropout layer\n",
        "\n",
        "      model.add(Dropout(0.2))\n",
        "\n",
        "=> Improving Performance of Simple Network: using different optimizers: SGD, Adagrad,Adam...\n",
        "\n",
        "=> Improving Performance of Simple Network: training for more number of epochs (20)\n",
        "\n",
        "=> other options to explore\n",
        "\n",
        "\n",
        "> different learning rate for optimizer\n",
        "\n",
        "> number of neurons in hidden layer\n",
        "\n",
        "> batch size\n",
        "\n",
        "> with different optimizers\n",
        "   \n",
        "> Increasing the number of internal hidden neurons\n",
        "   \n",
        "  \n",
        "=> steps to follow to make an efficient image classifier?\n",
        "     \n",
        "     >lot of experimentation and testing to get the optimal structure and parameters"
      ]
    }
  ]
}